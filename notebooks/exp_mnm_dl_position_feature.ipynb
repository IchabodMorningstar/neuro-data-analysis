{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUE_ON_T = 1.0\n",
    "SAMPLE_ON_T = SACCADE_ON_TIME = 3.0\n",
    "MNM_END_TIME = 3.0\n",
    "SUBREGIONS = {'Mid-Dorsal': 'MD', 'Posterior-Ventral': 'PV',\n",
    "              'Anterior-Dorsal': 'AD', 'Posterior-Dorsal': 'PD', 'Anterior-Ventral': 'AV'}\n",
    "\n",
    "def mat_to_df(dg, monkey, area, num_stimuli=1, numeric_cell=False, ):\n",
    "    rows = []\n",
    "    cells = []\n",
    "    for c in range(dg.shape[0]):\n",
    "        c_num = str(c + 1).zfill(3)\n",
    "        cell_name = f'{monkey}-{area}-{c_num}'\n",
    "        # cells.append([c + 1 if numeric_cell else cell_name, monkey, area])\n",
    "        for p in range(dg.shape[1]):\n",
    "            feature_names = dg[c][p][0].dtype.names\n",
    "            for t in range(dg[c, p].shape[1]):\n",
    "                cue_on_t = dg[c, p][0, t]['Cue_onT'][0][0]\n",
    "                ts = dg[c, p][0, t]['TS'].flatten()\n",
    "                if num_stimuli == 1:\n",
    "                    ts = ts - cue_on_t + CUE_ON_T\n",
    "                    ts = np.array([t for t in ts if t >= 0 and t <=\n",
    "                                  SACCADE_ON_TIME + 1.0], dtype=np.float32)\n",
    "                    if (len(ts) > 0):\n",
    "                        rows.append([cell_name, p, t, ts])  # , cue_on_t])\n",
    "                else:\n",
    "                    sample_on_t = dg[c, p][0, t]['Sample_onT'][0][0]\n",
    "                    ts2 = np.array([SAMPLE_ON_T + t - sample_on_t for t in ts if t >\n",
    "                                   sample_on_t and t <= sample_on_t + MNM_END_TIME], dtype=np.float32)\n",
    "                    ts = np.array([t - cue_on_t + CUE_ON_T for t in ts if t >= cue_on_t -\n",
    "                                  CUE_ON_T and t <= cue_on_t + SAMPLE_ON_T - CUE_ON_T], dtype=np.float32)\n",
    "                    ts = np.concatenate((ts, ts2))\n",
    "                    try:\n",
    "                        ismatch = dg[c, p][0, t]['IsMatch'][0][0]\n",
    "                        if len(ts) > 0:\n",
    "                            rows.append([c + 1, p, t, ts, ismatch])\n",
    "                    except:\n",
    "                        pass\n",
    " \n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "                      'cell', 'position', 'trial', 'ts'] + ([] if num_stimuli == 1 else ['ismatch']))\n",
    "    # df = df.set_index(['cell', 'position', 'trial'])\n",
    "    # , pd.DataFrame(cells, columns=['cell', 'monkey', 'area']).set_index('cell')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cells(df, style='monkey-area'):\n",
    "    cells = df.cell.unique()\n",
    "    cells = pd.DataFrame(cells, columns=['cell'])\n",
    "    cells['monkey'] = cells.cell.apply(lambda x: x.split('-')[0])\n",
    "    cells['area'] = cells.cell.apply(lambda x: x.split('-')[1])\n",
    "    if 'subregion' in style:\n",
    "        cells['subregion'] = cells.cell.apply(lambda x: x.split('-')[2])\n",
    "    if 'phase' in style:\n",
    "        cells['phase'] = cells.cell.apply(lambda x: x.split('-')[3])\n",
    "    cells = cells.set_index('cell')\n",
    "    return cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnm_feature():\n",
    "    asd_mat = loadmat(\n",
    "        '../../../data/MNM_original_data/all_feature_data.mat')['all_feature_data']\n",
    "    asi_mat = loadmat(\n",
    "        '../../../data/MNM_original_data/all_feature_info.mat')['all_feature_info']\n",
    "\n",
    "    asd_mat = asd_mat[:, :8]\n",
    "    asi_mat = asi_mat[:, [0, 3, 4]]\n",
    "    extract = np.vectorize(lambda x: x[0])\n",
    "    asi_mat = extract(asi_mat)\n",
    "\n",
    "    asi_df = pd.DataFrame(asi_mat, columns=['monkey', 'phase', 'subregion'])\n",
    "    asi_df.monkey = asi_df.monkey.apply(lambda x: x[0:3].upper())\n",
    "    asi_df.subregion = asi_df.subregion.apply(lambda x: SUBREGIONS[x].upper())\n",
    "\n",
    "    asd_df = mat_to_df(asd_mat, '<REPLACE>', 'PFC',\n",
    "                        num_stimuli=2, numeric_cell=True)\n",
    "\n",
    "    df = pd.merge(asd_df, asi_df, left_on='cell', right_index=True)\n",
    "    df['cell'] = df.apply(lambda r: '-'.join([r.monkey, 'PFC',\n",
    "                          str(r.subregion), r.phase, str(r.cell)]), axis=1)\n",
    "    cells = get_cells(df, style='monkey-area-subregion-phase')\n",
    "    df = df.drop(columns=['monkey', 'subregion', 'phase'])\n",
    "\n",
    "    return {'raw_df': df.set_index(['cell', 'position', 'trial']), 'cells': cells}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = load_mnm_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame(df_dict['raw_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = pd.DataFrame(df_dict['cells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index to move 'cell', 'position', and 'trial' back to columns\n",
    "raw_df = raw_df.reset_index()\n",
    "\n",
    "# Verify the change by printing the columns\n",
    "# raw_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>position</th>\n",
       "      <th>trial</th>\n",
       "      <th>ts</th>\n",
       "      <th>ismatch</th>\n",
       "      <th>monkey</th>\n",
       "      <th>area</th>\n",
       "      <th>subregion</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246366</th>\n",
       "      <td>517-PFC-PD-POST-2211</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>[0.12185, 1.626125, 2.1231, 2.373875, 2.557375...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517</td>\n",
       "      <td>PFC</td>\n",
       "      <td>PD</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207260</th>\n",
       "      <td>508-PFC-MD-POST-1797</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.149525, 2.444025, 3.2022, 4.755125]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508</td>\n",
       "      <td>PFC</td>\n",
       "      <td>MD</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254326</th>\n",
       "      <td>619-PFC-PV-POST-2306</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[0.04865, 0.52065, 0.53145, 2.328925, 2.43565,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>PFC</td>\n",
       "      <td>PV</td>\n",
       "      <td>POST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell  position  trial  \\\n",
       "246366  517-PFC-PD-POST-2211         5     11   \n",
       "207260  508-PFC-MD-POST-1797         3      0   \n",
       "254326  619-PFC-PV-POST-2306         4      9   \n",
       "\n",
       "                                                       ts  ismatch monkey  \\\n",
       "246366  [0.12185, 1.626125, 2.1231, 2.373875, 2.557375...      0.0    517   \n",
       "207260             [1.149525, 2.444025, 3.2022, 4.755125]      0.0    508   \n",
       "254326  [0.04865, 0.52065, 0.53145, 2.328925, 2.43565,...      0.0    619   \n",
       "\n",
       "       area subregion phase  \n",
       "246366  PFC        PD  POST  \n",
       "207260  PFC        MD  POST  \n",
       "254326  PFC        PV  POST  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(raw_df, cells, on='cell', how='inner')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = df.ts.apply(lambda x: len(x))\n",
    "# lengths.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df\n",
    "filtered_df['ts_length'] = filtered_df['ts'].apply(len)\n",
    "average_ts_length = filtered_df.groupby('cell')['ts_length'].mean().reset_index()\n",
    "sum_ts_length = filtered_df.groupby('cell')['ts_length'].sum().reset_index()\n",
    "use_cell = average_ts_length[(average_ts_length.ts_length >= 100) & (sum_ts_length.ts_length >= 500)].cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10806, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filtered_df[filtered_df['cell'].isin(use_cell)]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6411, 10), (4395, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = filtered_df[filtered_df.phase == \"PRE\"]\n",
    "post_df = filtered_df[filtered_df.phase == \"POST\"]\n",
    "pre_df.shape, post_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_soft_one_hot(pos):\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            0.6 if pos == x else (0.2 if abs(x - pos) ==\n",
    "                                  1 or abs(x - pos) == 7 else 0)\n",
    "            for x in range(1, 9)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def create_y(l, func):\n",
    "    return torch.hstack(\n",
    "        [\n",
    "            torch.stack([func(y) for y in l]),\n",
    "            torch.tensor(l).unsqueeze(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def window_data(df, NUM_OF_SAMPLES, WINDOW_STRIDE, WINDOW_WIDTH, NUM_POSITIONS, NUM_OF_CELLS):\n",
    "    df = df.sort_values(['cell', 'position']).reset_index(drop=True)\n",
    "\n",
    "    window_data = []\n",
    "    for start in np.arange(1, 3.5, WINDOW_STRIDE):\n",
    "        window_data.append(df.ts.apply(lambda x: (\n",
    "            (x >= start) & (x < start + WINDOW_WIDTH)).sum()).array)\n",
    "\n",
    "    window_d_t = torch.tensor(window_data).T\n",
    "    BINS = window_d_t.shape[1]\n",
    "\n",
    "    X = torch.zeros((NUM_OF_SAMPLES * NUM_POSITIONS,\n",
    "                    NUM_OF_CELLS * BINS), dtype=torch.float32)\n",
    "    y = []\n",
    "    for p in range(1, NUM_POSITIONS+1):\n",
    "        y += [p] * NUM_OF_SAMPLES\n",
    "        cells_idxs = df[df.position == p-1].groupby(\"cell\", sort=False).apply(\n",
    "            lambda x: x.index)\n",
    "        for i, cell_idxs in enumerate(cells_idxs):\n",
    "            idxs = np.random.choice(cell_idxs, NUM_OF_SAMPLES)\n",
    "            for j, idx in enumerate(idxs):\n",
    "                X[(p - 1) * NUM_OF_SAMPLES + j, i *\n",
    "                  BINS: (i + 1) * BINS] = window_d_t[idx]\n",
    "\n",
    "    return X, create_y(y, get_soft_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "NUM_OF_CELLS = pre_df.cell.nunique()\n",
    "NUM_OF_SAMPLES = 40\n",
    "WINDOW_STRIDE = 0.4\n",
    "WINDOW_WIDTH = 0.4\n",
    "NUM_POSITIONS = 2\n",
    "\n",
    "X, y = window_data(pre_df, NUM_OF_SAMPLES, WINDOW_STRIDE, WINDOW_WIDTH, NUM_POSITIONS, NUM_OF_CELLS)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 378])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.8824, Accuracy: 40.62%\n",
      "Epoch [2/20], Loss: 1.3893, Accuracy: 60.94%\n",
      "Epoch [3/20], Loss: 0.6003, Accuracy: 71.88%\n",
      "Epoch [4/20], Loss: 0.3930, Accuracy: 81.25%\n",
      "Epoch [5/20], Loss: 0.4483, Accuracy: 78.12%\n",
      "Epoch [6/20], Loss: 0.1513, Accuracy: 93.75%\n",
      "Epoch [7/20], Loss: 0.2052, Accuracy: 90.62%\n",
      "Epoch [8/20], Loss: 0.0948, Accuracy: 95.31%\n",
      "Epoch [9/20], Loss: 0.0598, Accuracy: 98.44%\n",
      "Epoch [10/20], Loss: 0.0853, Accuracy: 96.88%\n",
      "Epoch [11/20], Loss: 0.0345, Accuracy: 98.44%\n",
      "Epoch [12/20], Loss: 0.0279, Accuracy: 100.00%\n",
      "Epoch [13/20], Loss: 0.0333, Accuracy: 100.00%\n",
      "Epoch [14/20], Loss: 0.0220, Accuracy: 100.00%\n",
      "Epoch [15/20], Loss: 0.0131, Accuracy: 100.00%\n",
      "Epoch [16/20], Loss: 0.0112, Accuracy: 100.00%\n",
      "Epoch [17/20], Loss: 0.0139, Accuracy: 100.00%\n",
      "Epoch [18/20], Loss: 0.0128, Accuracy: 100.00%\n",
      "Epoch [19/20], Loss: 0.0094, Accuracy: 100.00%\n",
      "Epoch [20/20], Loss: 0.0068, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = X.shape[1]\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = SimpleFNN(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0064, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0064, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.1972, Accuracy: 42.19%\n",
      "Epoch [2/30], Loss: 0.8183, Accuracy: 57.81%\n",
      "Epoch [3/30], Loss: 0.7072, Accuracy: 59.38%\n",
      "Epoch [4/30], Loss: 0.6063, Accuracy: 73.44%\n",
      "Epoch [5/30], Loss: 0.5579, Accuracy: 76.56%\n",
      "Epoch [6/30], Loss: 0.4928, Accuracy: 82.81%\n",
      "Epoch [7/30], Loss: 0.4674, Accuracy: 78.12%\n",
      "Epoch [8/30], Loss: 0.3945, Accuracy: 84.38%\n",
      "Epoch [9/30], Loss: 0.3839, Accuracy: 84.38%\n",
      "Epoch [10/30], Loss: 0.3229, Accuracy: 85.94%\n",
      "Epoch [11/30], Loss: 0.3078, Accuracy: 84.38%\n",
      "Epoch [12/30], Loss: 0.2408, Accuracy: 93.75%\n",
      "Epoch [13/30], Loss: 0.2329, Accuracy: 95.31%\n",
      "Epoch [14/30], Loss: 0.1947, Accuracy: 87.50%\n",
      "Epoch [15/30], Loss: 0.1750, Accuracy: 95.31%\n",
      "Epoch [16/30], Loss: 0.1334, Accuracy: 96.88%\n",
      "Epoch [17/30], Loss: 0.1130, Accuracy: 96.88%\n",
      "Epoch [18/30], Loss: 0.0930, Accuracy: 100.00%\n",
      "Epoch [19/30], Loss: 0.0788, Accuracy: 100.00%\n",
      "Epoch [20/30], Loss: 0.0645, Accuracy: 100.00%\n",
      "Epoch [21/30], Loss: 0.0554, Accuracy: 100.00%\n",
      "Epoch [22/30], Loss: 0.0442, Accuracy: 100.00%\n",
      "Epoch [23/30], Loss: 0.0356, Accuracy: 100.00%\n",
      "Epoch [24/30], Loss: 0.0302, Accuracy: 100.00%\n",
      "Epoch [25/30], Loss: 0.0245, Accuracy: 100.00%\n",
      "Epoch [26/30], Loss: 0.0190, Accuracy: 100.00%\n",
      "Epoch [27/30], Loss: 0.0158, Accuracy: 100.00%\n",
      "Epoch [28/30], Loss: 0.0137, Accuracy: 100.00%\n",
      "Epoch [29/30], Loss: 0.0110, Accuracy: 100.00%\n",
      "Epoch [30/30], Loss: 0.0095, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_cells, bins, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_cells, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "BINS = 7\n",
    "num_cells = X.shape[1] // BINS\n",
    "bins = BINS\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = SimpleCNN(num_cells, bins, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.view(inputs.size(0), num_cells, bins)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0083, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0083, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion, num_cells, bins):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), num_cells, bins)  # Reshape the inputs to match the CNN input size\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, num_cells, bins)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.1174, Accuracy: 39.06%\n",
      "Epoch [2/100], Loss: 1.0535, Accuracy: 43.75%\n",
      "Epoch [3/100], Loss: 0.9959, Accuracy: 45.31%\n",
      "Epoch [4/100], Loss: 0.9409, Accuracy: 59.38%\n",
      "Epoch [5/100], Loss: 0.8858, Accuracy: 56.25%\n",
      "Epoch [6/100], Loss: 0.8416, Accuracy: 56.25%\n",
      "Epoch [7/100], Loss: 0.8066, Accuracy: 56.25%\n",
      "Epoch [8/100], Loss: 0.7778, Accuracy: 56.25%\n",
      "Epoch [9/100], Loss: 0.7574, Accuracy: 56.25%\n",
      "Epoch [10/100], Loss: 0.7411, Accuracy: 56.25%\n",
      "Epoch [11/100], Loss: 0.7282, Accuracy: 56.25%\n",
      "Epoch [12/100], Loss: 0.7179, Accuracy: 56.25%\n",
      "Epoch [13/100], Loss: 0.7084, Accuracy: 56.25%\n",
      "Epoch [14/100], Loss: 0.7003, Accuracy: 56.25%\n",
      "Epoch [15/100], Loss: 0.6919, Accuracy: 56.25%\n",
      "Epoch [16/100], Loss: 0.6828, Accuracy: 56.25%\n",
      "Epoch [17/100], Loss: 0.6755, Accuracy: 56.25%\n",
      "Epoch [18/100], Loss: 0.6667, Accuracy: 57.81%\n",
      "Epoch [19/100], Loss: 0.6545, Accuracy: 65.62%\n",
      "Epoch [20/100], Loss: 0.6448, Accuracy: 68.75%\n",
      "Epoch [21/100], Loss: 0.6336, Accuracy: 65.62%\n",
      "Epoch [22/100], Loss: 0.6226, Accuracy: 68.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 0.6122, Accuracy: 78.12%\n",
      "Epoch [24/100], Loss: 0.5945, Accuracy: 75.00%\n",
      "Epoch [25/100], Loss: 0.5792, Accuracy: 76.56%\n",
      "Epoch [26/100], Loss: 0.5760, Accuracy: 85.94%\n",
      "Epoch [27/100], Loss: 0.6212, Accuracy: 68.75%\n",
      "Epoch [28/100], Loss: 0.5876, Accuracy: 68.75%\n",
      "Epoch [29/100], Loss: 0.5484, Accuracy: 85.94%\n",
      "Epoch [30/100], Loss: 0.5367, Accuracy: 85.94%\n",
      "Epoch [31/100], Loss: 0.5112, Accuracy: 82.81%\n",
      "Epoch [32/100], Loss: 0.5175, Accuracy: 76.56%\n",
      "Epoch [33/100], Loss: 0.4927, Accuracy: 84.38%\n",
      "Epoch [34/100], Loss: 0.4842, Accuracy: 87.50%\n",
      "Epoch [35/100], Loss: 0.4611, Accuracy: 89.06%\n",
      "Epoch [36/100], Loss: 0.4523, Accuracy: 87.50%\n",
      "Epoch [37/100], Loss: 0.4320, Accuracy: 89.06%\n",
      "Epoch [38/100], Loss: 0.4179, Accuracy: 90.62%\n",
      "Epoch [39/100], Loss: 0.4412, Accuracy: 78.12%\n",
      "Epoch [40/100], Loss: 0.3891, Accuracy: 92.19%\n",
      "Epoch [41/100], Loss: 0.3853, Accuracy: 90.62%\n",
      "Epoch [42/100], Loss: 0.3602, Accuracy: 90.62%\n",
      "Epoch [43/100], Loss: 0.3420, Accuracy: 90.62%\n",
      "Epoch [44/100], Loss: 0.3395, Accuracy: 93.75%\n",
      "Epoch [45/100], Loss: 0.2998, Accuracy: 92.19%\n",
      "Epoch [46/100], Loss: 0.3147, Accuracy: 93.75%\n",
      "Epoch [47/100], Loss: 0.2864, Accuracy: 93.75%\n",
      "Epoch [48/100], Loss: 0.2526, Accuracy: 93.75%\n",
      "Epoch [49/100], Loss: 0.2483, Accuracy: 95.31%\n",
      "Epoch [50/100], Loss: 0.2379, Accuracy: 93.75%\n",
      "Epoch [51/100], Loss: 0.2174, Accuracy: 98.44%\n",
      "Epoch [52/100], Loss: 0.1923, Accuracy: 98.44%\n",
      "Epoch [53/100], Loss: 0.1735, Accuracy: 98.44%\n",
      "Epoch [54/100], Loss: 0.1661, Accuracy: 100.00%\n",
      "Epoch [55/100], Loss: 0.1618, Accuracy: 100.00%\n",
      "Epoch [56/100], Loss: 0.1377, Accuracy: 100.00%\n",
      "Epoch [57/100], Loss: 0.1339, Accuracy: 100.00%\n",
      "Epoch [58/100], Loss: 0.1160, Accuracy: 100.00%\n",
      "Epoch [59/100], Loss: 0.1161, Accuracy: 100.00%\n",
      "Epoch [60/100], Loss: 0.0980, Accuracy: 100.00%\n",
      "Epoch [61/100], Loss: 0.0927, Accuracy: 100.00%\n",
      "Epoch [62/100], Loss: 0.0866, Accuracy: 100.00%\n",
      "Epoch [63/100], Loss: 0.0812, Accuracy: 100.00%\n",
      "Epoch [64/100], Loss: 0.0747, Accuracy: 100.00%\n",
      "Epoch [65/100], Loss: 0.0709, Accuracy: 100.00%\n",
      "Epoch [66/100], Loss: 0.0682, Accuracy: 100.00%\n",
      "Epoch [67/100], Loss: 0.0641, Accuracy: 100.00%\n",
      "Epoch [68/100], Loss: 0.0611, Accuracy: 100.00%\n",
      "Epoch [69/100], Loss: 0.0584, Accuracy: 100.00%\n",
      "Epoch [70/100], Loss: 0.0560, Accuracy: 100.00%\n",
      "Epoch [71/100], Loss: 0.0536, Accuracy: 100.00%\n",
      "Epoch [72/100], Loss: 0.0514, Accuracy: 100.00%\n",
      "Epoch [73/100], Loss: 0.0496, Accuracy: 100.00%\n",
      "Epoch [74/100], Loss: 0.0478, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.0462, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.0445, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.0430, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.0415, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.0399, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.0386, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.0373, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.0360, Accuracy: 100.00%\n",
      "Epoch [83/100], Loss: 0.0350, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.0358, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.0340, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.0337, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.0320, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.0308, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.0297, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.0288, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.0281, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.0270, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.0262, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0254, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0247, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0239, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0233, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0227, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0221, Accuracy: 100.00%\n",
      "Epoch [100/100], Loss: 0.0215, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x[:, -1, :])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "num_features = BINS\n",
    "sequence_length = len(pre_df.cell.unique())\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = LSTMModel(num_features, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.view(inputs.size(0), sequence_length, num_features)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0211, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0211, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function for LSTM model\n",
    "def evaluate_model(model, test_loader, criterion, sequence_length, num_features):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), sequence_length, num_features)  # Reshape inputs\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, sequence_length, num_features)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "NUM_OF_CELLS = post_df.cell.nunique()\n",
    "NUM_OF_SAMPLES = 40\n",
    "WINDOW_STRIDE = 0.4\n",
    "WINDOW_WIDTH = 0.4\n",
    "NUM_POSITIONS = 2\n",
    "\n",
    "X, y = window_data(post_df, NUM_OF_SAMPLES, WINDOW_STRIDE, WINDOW_WIDTH, NUM_POSITIONS, NUM_OF_CELLS)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.9676, Accuracy: 40.62%\n",
      "Epoch [2/20], Loss: 1.2824, Accuracy: 54.69%\n",
      "Epoch [3/20], Loss: 1.0240, Accuracy: 65.62%\n",
      "Epoch [4/20], Loss: 0.8179, Accuracy: 59.38%\n",
      "Epoch [5/20], Loss: 0.3982, Accuracy: 78.12%\n",
      "Epoch [6/20], Loss: 0.6026, Accuracy: 67.19%\n",
      "Epoch [7/20], Loss: 0.2723, Accuracy: 92.19%\n",
      "Epoch [8/20], Loss: 0.4298, Accuracy: 76.56%\n",
      "Epoch [9/20], Loss: 0.2262, Accuracy: 92.19%\n",
      "Epoch [10/20], Loss: 0.2751, Accuracy: 89.06%\n",
      "Epoch [11/20], Loss: 0.1675, Accuracy: 95.31%\n",
      "Epoch [12/20], Loss: 0.1615, Accuracy: 95.31%\n",
      "Epoch [13/20], Loss: 0.1333, Accuracy: 98.44%\n",
      "Epoch [14/20], Loss: 0.1010, Accuracy: 95.31%\n",
      "Epoch [15/20], Loss: 0.0984, Accuracy: 96.88%\n",
      "Epoch [16/20], Loss: 0.0660, Accuracy: 100.00%\n",
      "Epoch [17/20], Loss: 0.0684, Accuracy: 100.00%\n",
      "Epoch [18/20], Loss: 0.0567, Accuracy: 100.00%\n",
      "Epoch [19/20], Loss: 0.0443, Accuracy: 100.00%\n",
      "Epoch [20/20], Loss: 0.0449, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class SimpleFNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_size = X.shape[1]\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = SimpleFNN(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0403, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0403, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.9112, Accuracy: 54.69%\n",
      "Epoch [2/30], Loss: 0.7836, Accuracy: 56.25%\n",
      "Epoch [3/30], Loss: 0.7085, Accuracy: 56.25%\n",
      "Epoch [4/30], Loss: 0.6664, Accuracy: 59.38%\n",
      "Epoch [5/30], Loss: 0.6421, Accuracy: 65.62%\n",
      "Epoch [6/30], Loss: 0.6124, Accuracy: 71.88%\n",
      "Epoch [7/30], Loss: 0.5870, Accuracy: 65.62%\n",
      "Epoch [8/30], Loss: 0.5657, Accuracy: 65.62%\n",
      "Epoch [9/30], Loss: 0.5235, Accuracy: 82.81%\n",
      "Epoch [10/30], Loss: 0.5117, Accuracy: 84.38%\n",
      "Epoch [11/30], Loss: 0.4693, Accuracy: 87.50%\n",
      "Epoch [12/30], Loss: 0.4443, Accuracy: 82.81%\n",
      "Epoch [13/30], Loss: 0.4062, Accuracy: 93.75%\n",
      "Epoch [14/30], Loss: 0.3566, Accuracy: 92.19%\n",
      "Epoch [15/30], Loss: 0.3439, Accuracy: 89.06%\n",
      "Epoch [16/30], Loss: 0.2781, Accuracy: 96.88%\n",
      "Epoch [17/30], Loss: 0.2669, Accuracy: 96.88%\n",
      "Epoch [18/30], Loss: 0.2397, Accuracy: 95.31%\n",
      "Epoch [19/30], Loss: 0.1950, Accuracy: 98.44%\n",
      "Epoch [20/30], Loss: 0.1700, Accuracy: 96.88%\n",
      "Epoch [21/30], Loss: 0.1325, Accuracy: 100.00%\n",
      "Epoch [22/30], Loss: 0.1179, Accuracy: 100.00%\n",
      "Epoch [23/30], Loss: 0.0886, Accuracy: 100.00%\n",
      "Epoch [24/30], Loss: 0.0728, Accuracy: 100.00%\n",
      "Epoch [25/30], Loss: 0.0587, Accuracy: 100.00%\n",
      "Epoch [26/30], Loss: 0.0447, Accuracy: 100.00%\n",
      "Epoch [27/30], Loss: 0.0368, Accuracy: 100.00%\n",
      "Epoch [28/30], Loss: 0.0278, Accuracy: 100.00%\n",
      "Epoch [29/30], Loss: 0.0232, Accuracy: 100.00%\n",
      "Epoch [30/30], Loss: 0.0175, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_cells, bins, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_cells, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "BINS = 7\n",
    "num_cells = X.shape[1] // BINS\n",
    "bins = BINS\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = SimpleCNN(num_cells, bins, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.view(inputs.size(0), num_cells, bins)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0147, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0147, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, criterion, num_cells, bins):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), num_cells, bins)  # Reshape the inputs to match the CNN input size\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, num_cells, bins)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.1337, Accuracy: 26.56%\n",
      "Epoch [2/100], Loss: 1.0835, Accuracy: 54.69%\n",
      "Epoch [3/100], Loss: 1.0371, Accuracy: 54.69%\n",
      "Epoch [4/100], Loss: 0.9900, Accuracy: 54.69%\n",
      "Epoch [5/100], Loss: 0.9486, Accuracy: 54.69%\n",
      "Epoch [6/100], Loss: 0.9094, Accuracy: 54.69%\n",
      "Epoch [7/100], Loss: 0.8784, Accuracy: 54.69%\n",
      "Epoch [8/100], Loss: 0.8535, Accuracy: 54.69%\n",
      "Epoch [9/100], Loss: 0.8326, Accuracy: 54.69%\n",
      "Epoch [10/100], Loss: 0.8141, Accuracy: 54.69%\n",
      "Epoch [11/100], Loss: 0.7983, Accuracy: 54.69%\n",
      "Epoch [12/100], Loss: 0.7846, Accuracy: 54.69%\n",
      "Epoch [13/100], Loss: 0.7729, Accuracy: 54.69%\n",
      "Epoch [14/100], Loss: 0.7632, Accuracy: 54.69%\n",
      "Epoch [15/100], Loss: 0.7548, Accuracy: 54.69%\n",
      "Epoch [16/100], Loss: 0.7487, Accuracy: 54.69%\n",
      "Epoch [17/100], Loss: 0.7427, Accuracy: 54.69%\n",
      "Epoch [18/100], Loss: 0.7379, Accuracy: 54.69%\n",
      "Epoch [19/100], Loss: 0.7338, Accuracy: 54.69%\n",
      "Epoch [20/100], Loss: 0.7298, Accuracy: 54.69%\n",
      "Epoch [21/100], Loss: 0.7257, Accuracy: 54.69%\n",
      "Epoch [22/100], Loss: 0.7212, Accuracy: 54.69%\n",
      "Epoch [23/100], Loss: 0.7230, Accuracy: 54.69%\n",
      "Epoch [24/100], Loss: 0.7144, Accuracy: 54.69%\n",
      "Epoch [25/100], Loss: 0.7126, Accuracy: 54.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 0.7068, Accuracy: 54.69%\n",
      "Epoch [27/100], Loss: 0.7112, Accuracy: 54.69%\n",
      "Epoch [28/100], Loss: 0.7051, Accuracy: 54.69%\n",
      "Epoch [29/100], Loss: 0.7023, Accuracy: 54.69%\n",
      "Epoch [30/100], Loss: 0.6973, Accuracy: 54.69%\n",
      "Epoch [31/100], Loss: 0.6869, Accuracy: 56.25%\n",
      "Epoch [32/100], Loss: 0.6835, Accuracy: 64.06%\n",
      "Epoch [33/100], Loss: 0.6795, Accuracy: 56.25%\n",
      "Epoch [34/100], Loss: 0.6674, Accuracy: 70.31%\n",
      "Epoch [35/100], Loss: 0.6566, Accuracy: 67.19%\n",
      "Epoch [36/100], Loss: 0.6459, Accuracy: 68.75%\n",
      "Epoch [37/100], Loss: 0.6864, Accuracy: 60.94%\n",
      "Epoch [38/100], Loss: 0.6766, Accuracy: 65.62%\n",
      "Epoch [39/100], Loss: 0.6984, Accuracy: 54.69%\n",
      "Epoch [40/100], Loss: 0.6899, Accuracy: 54.69%\n",
      "Epoch [41/100], Loss: 0.6780, Accuracy: 54.69%\n",
      "Epoch [42/100], Loss: 0.6781, Accuracy: 78.12%\n",
      "Epoch [43/100], Loss: 0.6684, Accuracy: 73.44%\n",
      "Epoch [44/100], Loss: 0.6645, Accuracy: 57.81%\n",
      "Epoch [45/100], Loss: 0.6510, Accuracy: 62.50%\n",
      "Epoch [46/100], Loss: 0.6384, Accuracy: 71.88%\n",
      "Epoch [47/100], Loss: 0.6394, Accuracy: 60.94%\n",
      "Epoch [48/100], Loss: 0.6296, Accuracy: 65.62%\n",
      "Epoch [49/100], Loss: 0.6181, Accuracy: 84.38%\n",
      "Epoch [50/100], Loss: 0.6036, Accuracy: 81.25%\n",
      "Epoch [51/100], Loss: 0.5985, Accuracy: 73.44%\n",
      "Epoch [52/100], Loss: 0.5784, Accuracy: 82.81%\n",
      "Epoch [53/100], Loss: 0.5605, Accuracy: 87.50%\n",
      "Epoch [54/100], Loss: 0.5377, Accuracy: 87.50%\n",
      "Epoch [55/100], Loss: 0.5322, Accuracy: 90.62%\n",
      "Epoch [56/100], Loss: 0.5206, Accuracy: 85.94%\n",
      "Epoch [57/100], Loss: 0.5132, Accuracy: 89.06%\n",
      "Epoch [58/100], Loss: 0.4802, Accuracy: 89.06%\n",
      "Epoch [59/100], Loss: 0.4751, Accuracy: 93.75%\n",
      "Epoch [60/100], Loss: 0.4748, Accuracy: 84.38%\n",
      "Epoch [61/100], Loss: 0.4391, Accuracy: 95.31%\n",
      "Epoch [62/100], Loss: 0.4287, Accuracy: 95.31%\n",
      "Epoch [63/100], Loss: 0.4311, Accuracy: 92.19%\n",
      "Epoch [64/100], Loss: 0.4422, Accuracy: 89.06%\n",
      "Epoch [65/100], Loss: 0.4270, Accuracy: 85.94%\n",
      "Epoch [66/100], Loss: 0.3738, Accuracy: 96.88%\n",
      "Epoch [67/100], Loss: 0.3745, Accuracy: 93.75%\n",
      "Epoch [68/100], Loss: 0.3662, Accuracy: 96.88%\n",
      "Epoch [69/100], Loss: 0.3290, Accuracy: 98.44%\n",
      "Epoch [70/100], Loss: 0.3216, Accuracy: 98.44%\n",
      "Epoch [71/100], Loss: 0.3075, Accuracy: 98.44%\n",
      "Epoch [72/100], Loss: 0.2843, Accuracy: 98.44%\n",
      "Epoch [73/100], Loss: 0.2704, Accuracy: 98.44%\n",
      "Epoch [74/100], Loss: 0.2524, Accuracy: 100.00%\n",
      "Epoch [75/100], Loss: 0.2432, Accuracy: 100.00%\n",
      "Epoch [76/100], Loss: 0.2289, Accuracy: 100.00%\n",
      "Epoch [77/100], Loss: 0.2276, Accuracy: 100.00%\n",
      "Epoch [78/100], Loss: 0.2301, Accuracy: 100.00%\n",
      "Epoch [79/100], Loss: 0.2143, Accuracy: 100.00%\n",
      "Epoch [80/100], Loss: 0.2020, Accuracy: 100.00%\n",
      "Epoch [81/100], Loss: 0.1783, Accuracy: 100.00%\n",
      "Epoch [82/100], Loss: 0.1863, Accuracy: 98.44%\n",
      "Epoch [83/100], Loss: 0.1668, Accuracy: 100.00%\n",
      "Epoch [84/100], Loss: 0.1641, Accuracy: 100.00%\n",
      "Epoch [85/100], Loss: 0.1619, Accuracy: 100.00%\n",
      "Epoch [86/100], Loss: 0.1404, Accuracy: 100.00%\n",
      "Epoch [87/100], Loss: 0.1412, Accuracy: 100.00%\n",
      "Epoch [88/100], Loss: 0.1332, Accuracy: 100.00%\n",
      "Epoch [89/100], Loss: 0.1234, Accuracy: 100.00%\n",
      "Epoch [90/100], Loss: 0.1152, Accuracy: 100.00%\n",
      "Epoch [91/100], Loss: 0.1116, Accuracy: 100.00%\n",
      "Epoch [92/100], Loss: 0.1049, Accuracy: 100.00%\n",
      "Epoch [93/100], Loss: 0.1020, Accuracy: 100.00%\n",
      "Epoch [94/100], Loss: 0.0950, Accuracy: 100.00%\n",
      "Epoch [95/100], Loss: 0.0927, Accuracy: 100.00%\n",
      "Epoch [96/100], Loss: 0.0885, Accuracy: 100.00%\n",
      "Epoch [97/100], Loss: 0.0847, Accuracy: 100.00%\n",
      "Epoch [98/100], Loss: 0.0818, Accuracy: 100.00%\n",
      "Epoch [99/100], Loss: 0.0779, Accuracy: 100.00%\n",
      "Epoch [100/100], Loss: 0.0751, Accuracy: 100.00%\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "y_train_labels = y_train[:, -1].long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "y_test_labels = y_test[:, -1].long()\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_labels)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x[:, -1, :])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "num_features = BINS\n",
    "sequence_length = len(post_df.cell.unique())\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = y_train_labels.max().item() + 1\n",
    "\n",
    "model = LSTMModel(num_features, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.view(inputs.size(0), sequence_length, num_features)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "print('Training Finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0732, Test Accuracy: 100.00%\n",
      "Final Test Loss: 0.0732, Final Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function for LSTM model\n",
    "def evaluate_model(model, test_loader, criterion, sequence_length, num_features):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), sequence_length, num_features)  # Reshape inputs\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_test_loss, accuracy\n",
    "\n",
    "# Evaluate the model after training\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, criterion, sequence_length, num_features)\n",
    "\n",
    "print(f'Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
